# exhibitions
Scripts for exhibition feedback analysis

## Карта скриптов: 
> *В необходимых файлах для доступного использования проставлены комментарии.*
---  
### 1. dp.py  
    Файл для подключения базы данных.  
> Как пользоваться?
* Изменить параметры для подключения к таблице в class DB
* Изменить sql скрипт на желаемый
* В последующих python файлах прописать `from db import data`
* Изменить параметры для подключения к таблице в class DB.
* Изменить sql скрипт на желаемый.
* В последующих python файлах прописать `from db import data`.
---  
### 2. semantic_files/
    папка со всем необходимым для удаления бессмысленных и ненужных комментариев.  
1. delete comments.py  
  Основной скрипт.  
2. vocab.txt  
  Кастомизированный словарь.  
3. fff.py  
  Скрипт, в котором присутствует проверка и на грамматические ошибки. Возможно когда-нибудь пригодится.
    Папка со всем необходимым для удаления бессмысленных и ненужных комментариев.  
**1. delete comments.py**  
`-` Основной скрипт.   
**2. vocab.txt**  
`-` Кастомизированный словарь.  
**3. fff.py**  
`-` Скрипт, в котором присутствует проверка и на грамматические ошибки. Возможно, когда-нибудь пригодится.
> Как пользоваться?  


* Изменить параметры для подключения к таблице **delete comments.py**  в class DB.
* Изменить ОБА!! sql в **delete comments.py** скрипта на желаемые. Необходимо заметить, что в данном файле также учитываются и ФИО гидов,
автоматически добавляясь в словарь. При желании отредактировать также и этот кусок кода.  
* Дополнить файл **vocab.txt** нужными словами. Необходимо учесть все формы слова, то есть если это существительное,
то прописать все падежи, если глагол все времена (рода можно не прописывать, скрипт допускает отличие на 1-2 буквы, но
все-таки желательно прописать, дабы избежать удаление слова при ошибке пользователя).
---  
### 3. sentiment_files/  
    Папка со всем необходимым для семантического анализа текста.  
**1. sentiment.py**  
`-` Основной скрипт.  
**2. model train.py**  
`-` Скрипт для тренировки модели.  
> Как пользоваться?
+ В файле **sentiment.py**  
    1. Прописать путь до модели `model = BertForSequenceClassification.from_pretrained('./fine_tuned_model')`.  
    2. Изменить параметры для подключения к таблице в class DB.
    3. Изменить ВСЕ!! sql скрипты на желаемые.
+ В файле **model train.py**
    1. Изменить название тренировочного файла `df = pd.read_csv('test.csv')`.
    2. По желанию изменить название папки, куда сохранится модель `save_directory = './fine_tuned_model'`.
+ Создание тренировочного файла **test.csv**  
    1. В DBeaver создать таблицу формата  

        | id | text          | label    |
        |----|:-------------:|---------:|
        | 1  | В восторге!   | POSITIVE |
       
       Обратите внимание, что название столбцов менять не надо!!  
    2. Затем экспортировать данные в формате CSV. И тестовый файл, и папка с моделью должны храниться в одной и той же папке, что и скрипт.
       
> *Гитхаб не позволил мне выгрузить файлы с готовыми моделями по причине большого веса, но в беседе тг они есть. :(*
---  
### 4. problematic_files/
    Папка со всем необходимым для анализа проблематизации комментариев.  
**1. problematic.py**  
`-` Основной скрипт.  
**2. problematic train.py**  
`-` Скрипт для тренировки модели.  
> Как пользоваться?
+ В файле **problematic.py**  
    1. Прописать путь до модели `lr = joblib.load('logistic_regression_model.pkl')`.  
    2. Изменить параметры для подключения к таблице в class DB.
    3. Изменить ВСЕ!! sql скрипты на желаемые.
+ В файле **problematic train.py**
    1. Изменить название тренировочного файла `banks = pd.read_csv('problem.csv', sep=',', index_col='id')`.
    2. По желанию изменить название папки, куда сохранится модель `joblib.dump(lr, 'logistic_regression_model.pkl')`.
+ Создание тренировочного файла **test.csv**  
    1. В DBeaver создать таблицу формата  

        | id | text          | score    |
        |----|:-------------:|---------:|
        | 1  | В восторге!   | POSITIVE |
       
       Обратите внимание, что название столбцов менять не надо!!  
    2. Затем экспортировать данные в формате CSV. И тестовый файл, и папка с моделью должны храниться в одной и той же папке, что и скрипт.
       
> *Гитхаб не позволил мне выгрузить файлы с готовыми моделями по причине большого веса, но в беседе тг они есть. :(*
---  
### 5. wordcloud_files/
    Папка со всем необходимым для создания облака слов.  
**1. wordcloud_.py**  
`-` Скрипт, который автоматически создает картинку.  
**2. info_for_wordcloud.py**  
`-` Скрипт, который выводит наиболее часто встречающиеся слова и словосочетания (каждое слово выводится столько раз, сколько встречается  
в таблице). Стоит ограничение на слова, которые встречались 3+ раз и 20 самых популярных словосочетаний.  
> Как пользоваться?
+ В файле **wordcloud_.py**
    1. Изменить параметры для подключения к таблице в class DB.
    2. Изменить sql скрипт на желаемый.
    3. Сохранить картинку.  
+ В файле **info_for_wordcloud.py**
    1. Если нужно изменить таблицу для подключения, то обратиться к файлу **db.py**, так как подключаем его в импорте.
    2. Можно настроить частоту слов и кол-во словосочетаний.
    3. Скопировать вывод и вставить куда нужно/дописать sql скрипт для выгрузки в таблицу. На ВФМ этим занимался Саша, но
  для дальнейшего использования я пропишу 2 вариант.
---  
### 5. language_files/
    Папка с файлом *language.py*, который определяет язык комментария. Если английских букв больше половины всех букв, то текст - английский (дабы исключить  
    возможность определения русских комментариев с англоязычными вставками как английских).
> Как пользоваться?
+ Сама программа выводит результат в консоль, поэтому нужно вызвать функцию для определения языка, предварительно прописав sql скрипт для вставки значения в нужный столбик таблицы. Для дальнейшего использования
  пропишу постоянный вариант.  
